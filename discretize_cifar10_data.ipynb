{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating HDF5 data\n",
    "** This notebook takes CIFAR10 data and generates hdf5 data for use as a layer in caffe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# As usual, a bit of setup\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cs231n.classifiers.cnn import *\n",
    "from cs231n.data_utils import get_CIFAR10_data\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "from cs231n.gradient_check import eval_numerical_gradient_array, eval_numerical_gradient\n",
    "from cs231n.layers import *\n",
    "from cs231n.fast_layers import *\n",
    "from cs231n.solver import Solver\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test:  (10000, 3, 32, 32)\n",
      "X_train:  (50000, 3, 32, 32)\n",
      "y_train:  (50000,)\n",
      "y_test:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the (preprocessed) CIFAR10 data.\n",
    "rawdata={}\n",
    "rawdata['X_train'],rawdata['y_train'],rawdata['X_test'],rawdata['y_test'] = load_CIFAR10('cs231n/datasets/cifar-10-batches-py')\n",
    "\n",
    "rawdata['X_train'] = rawdata['X_train'].transpose(0,3,1,2)\n",
    "rawdata['X_test'] = rawdata['X_test'].transpose(0,3,1,2)\n",
    "\n",
    "\n",
    "for k, v in rawdata.iteritems():\n",
    "    print '%s: ' % k, v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now output the hdf5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "script_dir = os.getcwd()\n",
    "\n",
    "#First discretize the data\n",
    "pts=128.0\n",
    "# Discretize the arrays\n",
    "rawdata['X_train_disc'] = (rawdata['X_train']//(256/pts))*(256/pts) + 0.5*(256/pts)\n",
    "rawdata['X_test_disc'] = (rawdata['X_test']//(256/pts))*(256/pts) + 0.5*(256/pts)\n",
    "rawdata['X_train_disc'][rawdata['X_train_disc'] > 255.0] = 255.0\n",
    "rawdata['X_test_disc'][rawdata['X_test_disc'] > 255.0] = 255.0\n",
    "\n",
    "\n",
    "\n",
    "meandisc_image = np.mean(rawdata['X_train_disc'], axis=0)\n",
    "mean_image = np.mean(rawdata['X_train'], axis=0)\n",
    "rawdata['X_train']-= mean_image\n",
    "rawdata['X_test']-= mean_image\n",
    "rawdata['X_train_disc']-= meandisc_image\n",
    "rawdata['X_test_disc']-= meandisc_image\n",
    "\n",
    "\n",
    "\n",
    "# Generate HDF5DataLayer sample_data.h5\n",
    "traindata=rawdata['X_train_disc']\n",
    "trainlabels = rawdata['y_train'][:,np.newaxis]\n",
    "traindata = traindata.astype('float32')\n",
    "\n",
    "testdata=rawdata['X_test_disc']\n",
    "testlabels = rawdata['y_test'][:,np.newaxis]\n",
    "testdata = testdata.astype('float32')\n",
    "\n",
    "with h5py.File(script_dir + '/cifar_train_disc128_gzip.h5', 'w') as f:\n",
    "    f.create_dataset(\n",
    "        'data', data=traindata,\n",
    "        compression='gzip', compression_opts=1\n",
    "    )\n",
    "    f.create_dataset(\n",
    "        'label', data=trainlabels,\n",
    "        compression='gzip', compression_opts=1,\n",
    "        dtype='uint8',\n",
    "    )\n",
    "    \n",
    "with h5py.File(script_dir + '/cifar_test_disc128_gzip.h5', 'w') as f:\n",
    "    f.create_dataset(\n",
    "        'data', data=testdata,\n",
    "        compression='gzip', compression_opts=1\n",
    "    )\n",
    "    f.create_dataset(\n",
    "        'label', data=testlabels,\n",
    "        compression='gzip', compression_opts=1,\n",
    "        dtype='uint8',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
