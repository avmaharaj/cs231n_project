net: "models/finetune_googlenet/train_val.prototxt"
test_iter: 200
test_interval: 500
# lr for fine-tuning should be lower than when starting from scratch
base_lr: 0.0001
type: "Adam"
momentum2 : 0.999
delta : 0.00000001
lr_policy: "step"
gamma: 0.5
# stepsize should also be lower, as we're closer to being done
stepsize: 1000
display: 20
max_iter: 5000
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "models/finetune_googlenet/tinyimage32"
# uncomment the following to default to CPU mode solving
solver_mode: GPU
